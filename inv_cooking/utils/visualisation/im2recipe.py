from typing import Optional, Dict, Any

import torch

from inv_cooking.datasets.recipe1m import Recipe1MDataModule
from inv_cooking.datasets.vocabulary import Vocabulary
from inv_cooking.training.image_to_recipe import ImageToRecipe


class Im2RecipeVisualiser:
    """
    Utils to visualise the recipes generated by im2recipe
    """

    def __init__(self, model: ImageToRecipe, data_module: Recipe1MDataModule):
        self.model = model
        self.data_module = data_module

    def visualize(self):
        """
        Function that combines the sampling of an input, passing through the model,
        and display of the result.

        Use the other functions individually for finer control.
        """
        batch = self.sample_input()
        batch, losses, ingr_predictions, recipe_predictions = self.sample_output(batch)
        self.display_sample(batch, losses, ingr_predictions, recipe_predictions)

    def sample_input(self):
        """
        Sample a batch input from the data loader
        """
        loader = self.data_module.test_dataloader()
        return next(iter(loader))

    def sample_output(self, batch: Optional[dict] = None, with_substitutions: bool = False):
        """
        Sample an output, using the batch as input to generate the outputs
        or generating a new sample input if not provided
        """
        if batch is None:
            batch = self.sample_input()

        ingredients = batch["ingredients"] if not with_substitutions else batch["substitution"]
        losses, (ingr_predictions, recipe_predictions) = self.model(
            image=batch["image"],
            ingredients=ingredients,
            recipe=batch["recipe"],
            use_ingr_pred=False,
            compute_losses=True,
            compute_predictions=True,
        )
        return batch, losses, ingr_predictions, recipe_predictions

    def display_sample(
        self, batch: Dict[str, Any], losses: Dict[str, Any], ingr_predictions: torch.Tensor,
        recipe_predictions: torch.Tensor, start: int = 0, limit: int = -1
    ):
        """
        Display the outputs of the model in terms of text
        """

        num_recipes = recipe_predictions.shape[0]
        ingr_vocab = self.data_module.dataset_test.ingr_vocab
        instr_vocab = self.data_module.dataset_test.get_instr_vocab()

        if limit < 0:
            limit = num_recipes
        else:
            limit = min(limit, num_recipes)

        for i in range(start, start + limit):
            print("INGREDIENTS (GT):")
            self.display_ingredients(batch["ingredients"][i], ingr_vocab)

            print("INGREDIENTS (SUBS):")
            self.display_ingredients(batch["substitution"][i], ingr_vocab)

            print("RECIPE (GT):")
            self.display_recipe(batch["recipe"][i], instr_vocab)

            if ingr_predictions is not None:
                print("INGREDIENTS (PRED):")
                self.display_ingredients(ingr_predictions[i], ingr_vocab)

            print("RECIPE (PRED):")
            self.display_recipe(recipe_predictions[i], instr_vocab)

    @staticmethod
    def display_ingredients(prediction: torch.Tensor, vocab: Vocabulary):
        ingredient_list = []
        for i in prediction.cpu().numpy():
            word = vocab.idx2word.get(i)
            if word != "<pad>":
                if isinstance(word, list):
                    ingredient_list.append(word[0])
                else:
                    ingredient_list.append(word)
        print(ingredient_list)

    @staticmethod
    def display_recipe(prediction: torch.Tensor, vocab: Vocabulary):
        sentence = ""
        for i in prediction.cpu().numpy():
            word = vocab.idx2word.get(i)
            if word == "<end>":
                print(sentence)
                break

            if word == "<eoi>":
                print(sentence)
                sentence = ""
            elif word != "<start>":
                sentence += " " + word
