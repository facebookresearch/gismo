# @package _group_

im2ingr:
  comment: 'default configuration for im2ingr'
  image_encoder: resnet50_encoder
  ingr_predictor: ingr_predictor_ff
  recipe_gen: recipe_gen_tf
  optimization:
    seed: 1235
    lr: 0.001
    scale_lr_pretrained: 0.01
    lr_decay_rate: 0.99
    lr_decay_every: 1
    weight_decay: 0.0
    max_epochs: 400
    patience: 10
    loss_weights:
      label_loss: 1.0
      cardinality_loss: 0.0
      eos_loss: 0.0

im2ingr_card_pred:
  parent: im2ingr
  ingr_predictor: ingr_predictor_ff_with_card_pred

im2ingr_tf:
  parent: im2ingr
  ingr_predictor: ingr_predictor_tf

im2ingr_resnext101_ff_bce:
  parent: im2ingr
  comment: 'best image-to-set results for resnext101 image backbone'
  image_encoder: resnext101_32x8d_encoder
  loading:
    batch_size: 8
  optimization:
    lr: 0.0001
    scale_lr_pretrained: 0.1

im2ingr_resnet50_ff_bce_cat:
  parent: im2ingr
  comment: 'best image-to-set results for resnet50 image backbone'
  ingr_predictor: ingr_predictor_ff_with_card_pred
  optimization:
    loss_weights:
      label_loss: 1.0
      cardinality_loss: 0.001
      eos_loss: 0.0

im2ingr_resnet50_ff_bce_cat_with_title:
  parent: im2ingr_resnet50_ff_bce_cat
  comment: 'Try if title helps predicting ingredient'
  title_encoder:
    with_title: true

im2ingr_resnext101_ff_bce_cat:
  parent: im2ingr_resnet50_ff_bce_cat
  comment: 'searching for ResNet101 CAT'
  image_encoder: resnext101_32x8d_encoder
  loading:
    batch_size: 6


# -----------------------------------------------------------------------------
# VIT based image encoders
# -----------------------------------------------------------------------------

im2ingr_vit_32_ff_bce_cat:
  parent: im2ingr_resnet50_ff_bce_cat
  comment: 'Try a VIT pretrained classification encoder'
  image_encoder:
     model: vit
     pretrained: True
     dropout: 0.1
     patch_size: 32
     n_cls_tokens: 1
     freeze: False

im2ingr_vit_16_ff_bce_cat:
  parent: im2ingr_vit_32_ff_bce_cat
  loading:
    batch_size: 8
  image_encoder:
    patch_size: 16

im2ingr_vit_32_no_class_ff_bce_cat:
  parent: im2ingr_resnet50_ff_bce_cat
  comment: 'VIT/32 pretrained classification encoder with average pooling instead of class tokens'
  loading:
    batch_size: 16
  image_encoder:
    model: vit
    pretrained: True
    dropout: 0.1
    patch_size: 32
    n_cls_tokens: 0
    freeze: False

im2ingr_vit_16_no_class_ff_bce_cat:
  parent: im2ingr_vit_32_no_class_ff_bce_cat
  comment: 'VIT/16 pretrained classification encoder with average pooling instead of class tokens'
  loading:
    batch_size: 12
  image_encoder:
    patch_size: 16
  optimization:
    patience: 20

im2ingr_vit_32_ff_bce_cat_multi_level:
  parent: im2ingr_vit_32_ff_bce_cat
  comment: 'VIT/32 pretrained model, with representation taken from multiple levels'
  image_encoder:
     additional_repr_levels: [6, 8, 10]
     concatenate_repr_levels: True

im2ingr_vit_16_ff_bce_cat_multi_level:
  parent: im2ingr_vit_16_ff_bce_cat
  comment: 'VIT/16 pretrained model, with representation taken from multiple levels'
  image_encoder:
     additional_repr_levels: [6, 8, 10]
     concatenate_repr_levels: True

im2ingr_vit_32_multi_class_no_head_bipartite:
  parent: im2ingr
  comment: 'Try with a multi class token VIT, where each token is an ingredient'
  loading:
    batch_size: 16
  image_encoder:
     model: vit
     pretrained: True
     dropout: 0.1
     patch_size: 32
     n_cls_tokens: 21
     freeze: False
  ingr_predictor:
    model: vit
    layers: 0
    embed_size: 2048
    with_set_prediction: bipartite
    dropout: 0.0
  optimization:
    loss_weights:
      label_loss: 1.0
      cardinality_loss: 0.0
      eos_loss: 0.001

im2ingr_vit_32_multi_class_no_head_pooled_set:
  parent: im2ingr_vit_32_multi_class_no_head_bipartite
  comment: 'Try with a multi class token VIT, where each token is an ingredient'
  ingr_predictor:
    with_set_prediction: pooled_bce

im2ingr_vit_32_multi_class_no_head_chamfer_l2_set:
  parent: im2ingr_vit_32_multi_class_no_head_bipartite
  comment: 'Try with a multi class token VIT, where each token is an ingredient'
  ingr_predictor:
    with_set_prediction: chamfer_l2

im2ingr_vit_32_multi_class_no_head_chamfer_ce_set:
  parent: im2ingr_vit_32_multi_class_no_head_bipartite
  comment: 'Try with a multi class token VIT, where each token is an ingredient'
  ingr_predictor:
    with_set_prediction: chamfer_ce

im2ingr_vit_32_multi_class_no_head_chamfer_unilat_ce_set:
  parent: im2ingr_vit_32_multi_class_no_head_bipartite
  comment: 'Try with a multi class token VIT, where each token is an ingredient'
  ingr_predictor:
    with_set_prediction: chamfer_unilateral_ce

im2ingr_vit_32_multi_class_no_head_list:
  parent: im2ingr_vit_32_multi_class_no_head_bipartite
  comment: 'Try with a multi class token VIT, where each token is an ingredient (but sensitive to order of ingredients)'
  ingr_predictor:
    with_set_prediction: none
  optimization:
    loss_weights:
      label_loss: 1.0
      cardinality_loss: 0.0
      eos_loss: 0.0


# -----------------------------------------------------------------------------
# CLIP based image encoders
# -----------------------------------------------------------------------------

im2ingr_clip_ff_bce_cat:
  parent: im2ingr_resnet50_ff_bce_cat
  comment: 'try the CLIP pre-trained encoder for the images (with fine-tuning)'
  image_encoder:
    model: clip_RN50
    pretrained: True
    dropout: 0.1
    freeze: False
  optimization:
    scale_lr_pretrained: SEARCH[0.1,1.0,0.01]

im2ingr_clip_vit_ff_bce_cat:
  parent: im2ingr_resnet50_ff_bce_cat
  comment: 'try the CLIP pre-trained encoder for the images (with fine-tuning)'
  image_encoder:
    model: clip_ViT-B/32
    pretrained: True
    dropout: 0.1
    freeze: False
  optimization:
    scale_lr_pretrained: 0.1
